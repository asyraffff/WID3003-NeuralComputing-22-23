{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9r_ybX-tBEvY"
      },
      "source": [
        "# Some PyTorch Tensor operation examples\n",
        "\n",
        "Firstly, creation of Tensors:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PXtKAsUwAvm2",
        "outputId": "82310e93-8a9e-4aab-915b-8bc3e6fe226f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[0., 0., 0.]])\n",
            "tensor([[1., 1., 1., 1., 1.],\n",
            "        [1., 1., 1., 1., 1.]])\n",
            "tensor([[1, 2, 3],\n",
            "        [4, 5, 6]], dtype=torch.int32)\n",
            "tensor([[1., 2., 3.],\n",
            "        [4., 5., 6.]])\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "# create an empty floating point tensor\n",
        "x = torch.empty(1,3)\n",
        "print(x)\n",
        "\n",
        "# Creation of default floating point tensor (float32) filled with ones\n",
        "y = torch.ones(2,5)\n",
        "print(y)\n",
        "\n",
        "# Creation of Integer tensor from existing data; The bad way (because you've _explicitly_ created a CPU-backed Tensor)\n",
        "zbad = torch.IntTensor([[1,2,3], [4, 5, 6]])\n",
        "print(zbad)\n",
        "\n",
        "# Creation of Integer tensor from existing data; The good way (this way allows you to specify device=... so it could be backed by the GPU)\n",
        "z = torch.tensor([[1, 2, 3], [4, 5, 6]], dtype=torch.float)\n",
        "print(z)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RNOsZ4DvBAUy"
      },
      "source": [
        "Inspecting a tensor:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ZGG-K1TAvm-",
        "outputId": "25677376-f0a1-4870-8788-8f43ad3c505b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([1, 3])\n",
            "torch.Size([1, 3])\n",
            "torch.FloatTensor\n",
            "cpu\n"
          ]
        }
      ],
      "source": [
        "print(x.size())\n",
        "print(x.shape) # usually used in preference to size()\n",
        "\n",
        "print(z.type()) # the underlying class; this will be dependent on the backing device\n",
        "print(z.device) # the actual backing device (which isn't just cpu/gpu, but could tell you which gpu)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JM9cD8v-GCsK"
      },
      "source": [
        "Setting values:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0tJstUUaAvnD",
        "outputId": "a651f316-8824-4a60-cafd-3931878748ea"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[0.0000, 1.1250, 1.1250]])\n",
            "tensor([[0.0000, 0.0000, 1.1250]])\n",
            "tensor([[1.1250, 1.1250, 1.1250]])\n"
          ]
        }
      ],
      "source": [
        "x[0,0] = 0 #setting a specific value\n",
        "print(x)\n",
        "\n",
        "x[0,1:2] = 0 #setting a range of values (the slice operator : works just like in numpy)\n",
        "print(x)\n",
        "\n",
        "# Setting all the values. Note all in-place operations are suffixed with an underscore\n",
        "x.fill_(1.125)\n",
        "print(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NL7uObp2Gqqx"
      },
      "source": [
        "1st-order statistics:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vGpUpvcnAvnI",
        "outputId": "6af1869a-7847-4661-9af4-5d77ca6b0829"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(1.1250)\n",
            "tensor(0.)\n"
          ]
        }
      ],
      "source": [
        "print(x.mean())\n",
        "print(x.std())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ifxQZtMVG64j"
      },
      "source": [
        "Note that the return type of these operations is a 0d Tensor:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UC5o5nxOG4V6",
        "outputId": "c1f5f3e3-09fe-49c6-c624-0e683f5fdd8d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([])\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "tensor(3.3750)"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "print(x.sum().shape)\n",
        "x.sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k7RL0Zj7HLhD"
      },
      "source": [
        "To get this back to a Python number:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tPlWse_mAvnP",
        "outputId": "a5510385-008a-4302-b3b9-c488a36fe00f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "3.375"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "## 0d tensor can be converted back to a Python scalar with item()\n",
        "x.sum().item()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WVksTK-MHqtK"
      },
      "source": [
        "You can also go straight to a numpy array:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CXQqXugOAvnT",
        "outputId": "06718c95-abd4-4bf4-ffd1-610e9ba6ad2b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[1., 2., 3.],\n",
              "       [4., 5., 6.]], dtype=float32)"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "z.numpy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I6SQfF3lIuHB"
      },
      "source": [
        "Note in both cases above, if the Tensor is not already on the CPU, you have to copy it there first otherwise you'll get an error:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0KtFLvvUI5I3",
        "outputId": "80417974-fae5-405d-bc61-fcf5d3b0dff4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[1. 2. 3.]\n",
            " [4. 5. 6.]]\n",
            "1.0\n"
          ]
        }
      ],
      "source": [
        "print(z.cpu().numpy())\n",
        "print(z[0,0].item())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7xgCRzGNJzxQ"
      },
      "source": [
        "Element-wise operations\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NmKXTNZsAvnw",
        "outputId": "795a295f-a25e-4307-8f96-0d75f5605173"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([21., 41., 61.])\n",
            "tensor([-1., -1., -1.])\n",
            "tensor([110., 420., 930.])\n",
            "tensor([0.9091, 0.9524, 0.9677])\n",
            "tensor([100., 400., 900.])\n",
            "tensor([-0.5440,  0.9129, -0.9880])\n",
            "tensor([ True, False, False])\n",
            "tensor([ True,  True, False])\n",
            "tensor([ True, False, False])\n"
          ]
        }
      ],
      "source": [
        "x = torch.tensor([ 10., 20., 30.])\n",
        "y = torch.tensor([ 11., 21., 31.])\n",
        "\n",
        "print(x + y) #Tensor-Tensor addition (element-wise addition)\n",
        "print(x - y) #Tensor-Tensor subtraction (element-wise subtraction)\n",
        "print(x * y) #Hadamard product of two tensors\n",
        "print(x / y) #Hadamard division of two tensors\n",
        "print(x**2) #raising to a power\n",
        "print(torch.sin(x)) #applying sin element-wise\n",
        "print(x == 10) #element-wise boolean tests\n",
        "print(x <= 20) #element-wise boolean tests\n",
        "print((x <= 20) & (x==10)) #element-wise logical `and`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K8t2E5piL0Wu"
      },
      "source": [
        "Matrix multiplication"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y-ES1RckAvnz",
        "outputId": "6865b115-8f11-4b86-8b54-b7045a07108a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error: mat2 must be a matrix\n",
            "tensor([30., 40., 30.])\n",
            "tensor([30., 40., 30.])\n"
          ]
        }
      ],
      "source": [
        "x = torch.tensor([ 10., 20., 30.]) #x is a 1d tensor\n",
        "m = torch.tensor([[ 0., 0., 1. ],[ 0., 2., 0. ],[ 3., 0., 0. ]]) #m is a 2d tensor\n",
        "\n",
        "try:\n",
        "  print(torch.mm(m,x)) #torch.mm performs matrix-matrix multiplication; this will fail because .mm doesn't support broadcasting and the inputs have differing tensor order\n",
        "except Exception as e:\n",
        "  print(\"Error: \" + str(e))\n",
        "print(torch.matmul(m,x)) #torch.matmul performs matrix-matrix multiplication with broadcasting; it will automatically convert x to a 2d tensor so the multiplication can be performed\n",
        "print(m @ x) #ampersand is convienent short-hand notation for matmul\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bhSwen88NnvG"
      },
      "source": [
        "Unsqueezing tensors - this is something you'll probably see a lot; unsqueezing  adds another dimension:  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iX5TaPmeAvn2",
        "outputId": "b97cf4dc-54df-4127-a0a6-9d8b580081c0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([3])\n",
            "torch.Size([3, 1])\n",
            "torch.Size([1, 3])\n",
            "tensor([[30.],\n",
            "        [40.],\n",
            "        [30.]])\n"
          ]
        }
      ],
      "source": [
        "x = torch.tensor([ 10., 20., 30.])\n",
        "print(x.shape)\n",
        "x.unsqueeze_(-1) #in-place unsqueeze, adding the new dimension in the last position (so we create a _column_ vector)\n",
        "print(x.shape)\n",
        "\n",
        "print(x.t().shape) #note .t() transposes a tensor\n",
        "\n",
        "print(torch.mm(m,x)) #  the previous .mm that failed because of mismatched sizes will now work"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5KLIXGL8NsoH"
      },
      "source": [
        "Sometimes we'll need to reshape tensors:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9r-PHr5CAvn5",
        "outputId": "0829f69c-de85-48f3-bea0-9cedf89ed442"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([10., 20., 30.])\n"
          ]
        }
      ],
      "source": [
        "x2 = x.reshape(3) # back to where we started!\n",
        "print(x2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nrbtLkJOXndQ"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.15"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
